{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ed47202-ceb3-47a2-aa4d-3e693f402880",
   "metadata": {},
   "source": [
    "## **Project: AI-Powered Job Insights Using RAG & FAISS**\n",
    "\n",
    "### **📌 Introduction**\n",
    "Finding the right job can be overwhelming. Job seekers and recruiters need **structured insights** into job trends, skills in demand, and salary distributions across locations. Traditional search mechanisms rely on keyword matching, which often leads to **irrelevant results**. This project aims to enhance **job insights** using **Retrieval-Augmented Generation (RAG)** and **FAISS-based indexing** to build a **powerful job search and analysis tool**.\n",
    "\n",
    "---\n",
    "\n",
    "### **🎯 Objective**\n",
    "The goal of this project is to:\n",
    "1. **Enhance job search** using **semantic search with FAISS indexing** instead of simple keyword-based searches.\n",
    "2. **Use RAG (Retrieval-Augmented Generation)** with ChatGPT to provide **smart job recommendations** based on queries.\n",
    "3. **Leverage Pandas AI Agent** to create **interactive visualizations**, like:\n",
    "   - Most in-demand skills by city.\n",
    "   - Salary comparison across locations and job roles.\n",
    "   - Heatmaps of job availability.\n",
    "   - Insights into recruiter trends.\n",
    "\n",
    "---\n",
    "\n",
    "## **🔍 What is RAG (Retrieval-Augmented Generation)?**\n",
    "**RAG** is an advanced AI technique that **combines retrieval-based search with generative models** like ChatGPT. Instead of relying on static model knowledge, RAG allows the model to **fetch real-time, relevant information** from an external database (FAISS in our case) before generating a response.\n",
    "\n",
    "**Key Benefits of RAG:**\n",
    "✅ Retrieves **up-to-date** information.  \n",
    "✅ Provides **contextually relevant** answers.  \n",
    "✅ Reduces **hallucination** in generative AI.  \n",
    "\n",
    "---\n",
    "\n",
    "## **⚡ What is FAISS & Why FAISS for Job Data?**\n",
    "**FAISS (Facebook AI Similarity Search)** is an efficient **vector search** library for **fast similarity searches**. \n",
    "\n",
    "🔹 Traditional databases are slow for **large-scale** text search.  \n",
    "🔹 FAISS **embeds** job descriptions as **vectors** and allows **fast retrieval** based on meaning (not keywords).  \n",
    "🔹 Ideal for **semantic search** of jobs based on user queries.\n",
    "\n",
    "---\n",
    "\n",
    "## **🚀 Features to Implement**\n",
    "### **1️⃣ Semantic Search for Jobs**\n",
    "- Convert job descriptions into **embeddings** using OpenAI’s embedding model.\n",
    "- Store embeddings in **FAISS** for fast retrieval.\n",
    "- Implement **semantic search** for job queries.\n",
    "\n",
    "### **2️⃣ ChatGPT-based RAG**\n",
    "- Use **retrieved job postings** from FAISS to **generate smart responses**.\n",
    "- Enable users to ask **detailed queries**, such as:\n",
    "  - _\"What are the best-paying jobs for Data Engineers in Bangalore?\"_\n",
    "  - _\"Which job roles require Azure & Python in Chennai?\"_\n",
    "\n",
    "### **3️⃣ AI-Powered Job Analytics**\n",
    "- **Pandas AI Agent** for exploratory data analysis.\n",
    "- **Top skills by city** (Bar chart).\n",
    "- **Salary comparison by job role & location** (Heatmap).\n",
    "- **Job availability across cities** (Geo-based visualization).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660b4b51-6713-4623-b940-3de126260dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (1.10.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (4.49.0)\n",
      "Requirement already satisfied: openai in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (1.63.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anuvadini-019\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "###. Install & Import Required Libraries\n",
    "# Install necessary libraries (only run once)\n",
    "!pip install pandas faiss-cpu sentence-transformers transformers openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22096ab5-4881-4f76-bd88-2ea0c94fa4a5",
   "metadata": {},
   "source": [
    "### **📌 Load & Prepare Job Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf2fafe1-0d4f-4f75-b093-b20453a1af8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuvadini-019\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Title</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Min Experience</th>\n",
       "      <th>Max Experience</th>\n",
       "      <th>Category ID</th>\n",
       "      <th>Job URL</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company ID</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Recruiter ID</th>\n",
       "      <th>Recruiter Name</th>\n",
       "      <th>Recruiter Designation</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Functional Area</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1432749</td>\n",
       "      <td>Job Description :Were Haleon. A new world-lead...</td>\n",
       "      <td>Haleon - Data Engineer - Azure Databricks/Data...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/haleon-data-engineer-...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3348</td>\n",
       "      <td>Hirist</td>\n",
       "      <td>180511</td>\n",
       "      <td>Talent Bridge</td>\n",
       "      <td>HR</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>Data Analysis / Business Analysis</td>\n",
       "      <td>Data Engineering, Data Pipeline, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1434028</td>\n",
       "      <td>Job Summary :We are looking for a fresher Data...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-analyst-1434028....</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2767</td>\n",
       "      <td>VIBRANTUM LABZ PRIVATE LIMITED</td>\n",
       "      <td>194867</td>\n",
       "      <td>swetha</td>\n",
       "      <td>hr</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>Data Analysis / Business Analysis</td>\n",
       "      <td>Data Analyst, Data Analytics, SQL, Reporting T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433670</td>\n",
       "      <td>Job Title : Data AnalystExperience : 6 months ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-analyst-1433670....</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>0</td>\n",
       "      <td>Creencia Technologies Pvt Ltd</td>\n",
       "      <td>57068</td>\n",
       "      <td>Aruna</td>\n",
       "      <td>Talent Acquisition Specialist</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Data Analysis / Business Analysis</td>\n",
       "      <td>Data Analyst, Data Analytics, Data Management,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434327</td>\n",
       "      <td>Job Description :Our Client works with a varie...</td>\n",
       "      <td>Data Engineer - Python/Spark</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-engineer-pythons...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>Fidius Advisory</td>\n",
       "      <td>132726</td>\n",
       "      <td>Priyanka Mohan</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Data Engineering, Python, Spark, Scala, Data M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433114</td>\n",
       "      <td>Job Description :- We are seeking a highly ski...</td>\n",
       "      <td>Data Engineer - Machine Learning</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-engineer-machine...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>Interon IT Solutions</td>\n",
       "      <td>212071</td>\n",
       "      <td>Charan Reddy</td>\n",
       "      <td>US IT Recruiter</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Machine Learning, Data Engineering, ETL, Azure...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Job ID                                    Job Description  \\\n",
       "0  1432749  Job Description :Were Haleon. A new world-lead...   \n",
       "1  1434028  Job Summary :We are looking for a fresher Data...   \n",
       "2  1433670  Job Title : Data AnalystExperience : 6 months ...   \n",
       "3  1434327  Job Description :Our Client works with a varie...   \n",
       "4  1433114  Job Description :- We are seeking a highly ski...   \n",
       "\n",
       "                                               Title    Designation  \\\n",
       "0  Haleon - Data Engineer - Azure Databricks/Data...  Data Engineer   \n",
       "1                                      Data Analyst    Data Analyst   \n",
       "2                                      Data Analyst    Data Analyst   \n",
       "3                      Data Engineer - Python/Spark   Data Engineer   \n",
       "4                  Data Engineer - Machine Learning   Data Engineer   \n",
       "\n",
       "   Min Experience  Max Experience  Category ID  \\\n",
       "0               5               9            7   \n",
       "1               0               3            7   \n",
       "2               0               2            7   \n",
       "3               2              10            7   \n",
       "4               7              10            7   \n",
       "\n",
       "                                             Job URL          Location  \\\n",
       "0  https://www.hirist.com/j/haleon-data-engineer-...         Bangalore   \n",
       "1  https://www.hirist.com/j/data-analyst-1434028....           Chennai   \n",
       "2  https://www.hirist.com/j/data-analyst-1433670....  Gurgaon/Gurugram   \n",
       "3  https://www.hirist.com/j/data-engineer-pythons...         Bangalore   \n",
       "4  https://www.hirist.com/j/data-engineer-machine...         Bangalore   \n",
       "\n",
       "   Company ID                    Company Name  Recruiter ID  Recruiter Name  \\\n",
       "0        3348                          Hirist        180511   Talent Bridge   \n",
       "1        2767  VIBRANTUM LABZ PRIVATE LIMITED        194867          swetha   \n",
       "2           0   Creencia Technologies Pvt Ltd         57068           Aruna   \n",
       "3           0                 Fidius Advisory        132726  Priyanka Mohan   \n",
       "4           0            Interon IT Solutions        212071    Charan Reddy   \n",
       "\n",
       "           Recruiter Designation  Min Salary  Max Salary  \\\n",
       "0                             HR          15          27   \n",
       "1                             hr           6          12   \n",
       "2  Talent Acquisition Specialist           7           8   \n",
       "3                     Consultant           8          30   \n",
       "4                US IT Recruiter          20          30   \n",
       "\n",
       "                     Functional Area  \\\n",
       "0  Data Analysis / Business Analysis   \n",
       "1  Data Analysis / Business Analysis   \n",
       "2  Data Analysis / Business Analysis   \n",
       "3                   Data Engineering   \n",
       "4                   Data Engineering   \n",
       "\n",
       "                                              Skills  \n",
       "0  Data Engineering, Data Pipeline, Data Architec...  \n",
       "1  Data Analyst, Data Analytics, SQL, Reporting T...  \n",
       "2  Data Analyst, Data Analytics, Data Management,...  \n",
       "3  Data Engineering, Python, Spark, Scala, Data M...  \n",
       "4  Machine Learning, Data Engineering, ETL, Azure...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"hirist.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Function to clean HTML tags from text\n",
    "def clean_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text() if pd.notna(text) else \"\"\n",
    "\n",
    "# Apply the cleaning function to the Job Description column\n",
    "df['Job Description'] = df['Job Description'].apply(clean_html)\n",
    "\n",
    "# Display sample data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8007c975-451c-4581-87c5-fc4ab2bf417d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Title</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Min Experience</th>\n",
       "      <th>Max Experience</th>\n",
       "      <th>Category ID</th>\n",
       "      <th>Job URL</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company ID</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Recruiter ID</th>\n",
       "      <th>Recruiter Name</th>\n",
       "      <th>Recruiter Designation</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>Functional Area</th>\n",
       "      <th>Skills</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1432749</td>\n",
       "      <td>Job Description :Were Haleon. A new world-lead...</td>\n",
       "      <td>Haleon - Data Engineer - Azure Databricks/Data...</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/haleon-data-engineer-...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3348</td>\n",
       "      <td>Hirist</td>\n",
       "      <td>180511</td>\n",
       "      <td>Talent Bridge</td>\n",
       "      <td>HR</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>Data Analysis / Business Analysis</td>\n",
       "      <td>Data Engineering, Data Pipeline, Data Architec...</td>\n",
       "      <td>Job ID: 1432749 | Job Description: Job Descrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1434028</td>\n",
       "      <td>Job Summary :We are looking for a fresher Data...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-analyst-1434028....</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2767</td>\n",
       "      <td>VIBRANTUM LABZ PRIVATE LIMITED</td>\n",
       "      <td>194867</td>\n",
       "      <td>swetha</td>\n",
       "      <td>hr</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>Data Analysis / Business Analysis</td>\n",
       "      <td>Data Analyst, Data Analytics, SQL, Reporting T...</td>\n",
       "      <td>Job ID: 1434028 | Job Description: Job Summary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433670</td>\n",
       "      <td>Job Title : Data AnalystExperience : 6 months ...</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-analyst-1433670....</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>0</td>\n",
       "      <td>Creencia Technologies Pvt Ltd</td>\n",
       "      <td>57068</td>\n",
       "      <td>Aruna</td>\n",
       "      <td>Talent Acquisition Specialist</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Data Analysis / Business Analysis</td>\n",
       "      <td>Data Analyst, Data Analytics, Data Management,...</td>\n",
       "      <td>Job ID: 1433670 | Job Description: Job Title :...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434327</td>\n",
       "      <td>Job Description :Our Client works with a varie...</td>\n",
       "      <td>Data Engineer - Python/Spark</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-engineer-pythons...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>Fidius Advisory</td>\n",
       "      <td>132726</td>\n",
       "      <td>Priyanka Mohan</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Data Engineering, Python, Spark, Scala, Data M...</td>\n",
       "      <td>Job ID: 1434327 | Job Description: Job Descrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433114</td>\n",
       "      <td>Job Description :- We are seeking a highly ski...</td>\n",
       "      <td>Data Engineer - Machine Learning</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.hirist.com/j/data-engineer-machine...</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>0</td>\n",
       "      <td>Interon IT Solutions</td>\n",
       "      <td>212071</td>\n",
       "      <td>Charan Reddy</td>\n",
       "      <td>US IT Recruiter</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>Data Engineering</td>\n",
       "      <td>Machine Learning, Data Engineering, ETL, Azure...</td>\n",
       "      <td>Job ID: 1433114 | Job Description: Job Descrip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Job ID                                    Job Description  \\\n",
       "0  1432749  Job Description :Were Haleon. A new world-lead...   \n",
       "1  1434028  Job Summary :We are looking for a fresher Data...   \n",
       "2  1433670  Job Title : Data AnalystExperience : 6 months ...   \n",
       "3  1434327  Job Description :Our Client works with a varie...   \n",
       "4  1433114  Job Description :- We are seeking a highly ski...   \n",
       "\n",
       "                                               Title    Designation  \\\n",
       "0  Haleon - Data Engineer - Azure Databricks/Data...  Data Engineer   \n",
       "1                                      Data Analyst    Data Analyst   \n",
       "2                                      Data Analyst    Data Analyst   \n",
       "3                      Data Engineer - Python/Spark   Data Engineer   \n",
       "4                  Data Engineer - Machine Learning   Data Engineer   \n",
       "\n",
       "   Min Experience  Max Experience  Category ID  \\\n",
       "0               5               9            7   \n",
       "1               0               3            7   \n",
       "2               0               2            7   \n",
       "3               2              10            7   \n",
       "4               7              10            7   \n",
       "\n",
       "                                             Job URL          Location  \\\n",
       "0  https://www.hirist.com/j/haleon-data-engineer-...         Bangalore   \n",
       "1  https://www.hirist.com/j/data-analyst-1434028....           Chennai   \n",
       "2  https://www.hirist.com/j/data-analyst-1433670....  Gurgaon/Gurugram   \n",
       "3  https://www.hirist.com/j/data-engineer-pythons...         Bangalore   \n",
       "4  https://www.hirist.com/j/data-engineer-machine...         Bangalore   \n",
       "\n",
       "   Company ID                    Company Name  Recruiter ID  Recruiter Name  \\\n",
       "0        3348                          Hirist        180511   Talent Bridge   \n",
       "1        2767  VIBRANTUM LABZ PRIVATE LIMITED        194867          swetha   \n",
       "2           0   Creencia Technologies Pvt Ltd         57068           Aruna   \n",
       "3           0                 Fidius Advisory        132726  Priyanka Mohan   \n",
       "4           0            Interon IT Solutions        212071    Charan Reddy   \n",
       "\n",
       "           Recruiter Designation  Min Salary  Max Salary  \\\n",
       "0                             HR          15          27   \n",
       "1                             hr           6          12   \n",
       "2  Talent Acquisition Specialist           7           8   \n",
       "3                     Consultant           8          30   \n",
       "4                US IT Recruiter          20          30   \n",
       "\n",
       "                     Functional Area  \\\n",
       "0  Data Analysis / Business Analysis   \n",
       "1  Data Analysis / Business Analysis   \n",
       "2  Data Analysis / Business Analysis   \n",
       "3                   Data Engineering   \n",
       "4                   Data Engineering   \n",
       "\n",
       "                                              Skills  \\\n",
       "0  Data Engineering, Data Pipeline, Data Architec...   \n",
       "1  Data Analyst, Data Analytics, SQL, Reporting T...   \n",
       "2  Data Analyst, Data Analytics, Data Management,...   \n",
       "3  Data Engineering, Python, Spark, Scala, Data M...   \n",
       "4  Machine Learning, Data Engineering, ETL, Azure...   \n",
       "\n",
       "                                       combined_text  \n",
       "0  Job ID: 1432749 | Job Description: Job Descrip...  \n",
       "1  Job ID: 1434028 | Job Description: Job Summary...  \n",
       "2  Job ID: 1433670 | Job Description: Job Title :...  \n",
       "3  Job ID: 1434327 | Job Description: Job Descrip...  \n",
       "4  Job ID: 1433114 | Job Description: Job Descrip...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# 🔹 LOAD & PREPARE JOB DATASET\n",
    "# ============================\n",
    "\n",
    "\"\"\"\n",
    "In this section, we prepare job listings in a structured format.\n",
    "Each job has multiple fields (Title, Company, Location, Skills, Experience).\n",
    "To make it searchable, we merge all fields into a single text string.\n",
    "\"\"\"\n",
    "\n",
    "# Convert job postings into a structured search-friendly format\n",
    "df[\"combined_text\"] = df.apply(lambda row: \" | \".join([f\"{col}: {row[col]}\" for col in df.columns if col != \"combined_text\"]), axis=1)\n",
    "\n",
    "# Display sample data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d60a22-0862-4b0f-b40a-db9b0627d7f3",
   "metadata": {},
   "source": [
    "### **📌 Generate Embeddings for Jobs**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "512d9bc4-f1ab-4832-bef5-cd272f50f857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anuvadini-019\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Anuvadini-019\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: (363, 384)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "To enable similarity search, we convert job descriptions into dense embeddings using\n",
    "the `all-MiniLM-L6-v2` model from Sentence Transformers.\n",
    "\"\"\"\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings for all job postings\n",
    "job_descriptions = df[\"combined_text\"].tolist()\n",
    "job_embeddings = embedding_model.encode(job_descriptions, convert_to_numpy=True)\n",
    "\n",
    "# Check embedding shape (should be [num_jobs, embedding_dim])\n",
    "print(f\"Embedding Shape: {job_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa26d92-b9eb-4b15-a037-d6cd091d0133",
   "metadata": {},
   "source": [
    "### **📌 Set Up FAISS Index for Fast Similarity Search**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9bf885c-4a29-410f-8df9-bbfec329a7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index contains 363 job entries.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We use FAISS (Facebook AI Similarity Search) to create an index for efficient retrieval.\n",
    "It allows fast approximate nearest neighbor (ANN) search.\n",
    "\"\"\"\n",
    "\n",
    "import faiss\n",
    "\n",
    "# Define FAISS index\n",
    "dimension = job_embeddings.shape[1]  # Embedding dimension\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 (Euclidean) distance search\n",
    "index.add(job_embeddings)  # Add job embeddings to FAISS index\n",
    "\n",
    "# Store metadata for each job (Job ID, Title, URL, Salary, etc.)\n",
    "job_metadata_map = {\n",
    "    i: {\n",
    "        \"Job ID\": df.loc[i, \"Job ID\"],\n",
    "        \"Title\": df.loc[i, \"Title\"],\n",
    "        \"Job URL\": df.loc[i, \"Job URL\"],\n",
    "        \"Salary\": f\"{df.loc[i, 'Min Salary']} - {df.loc[i, 'Max Salary']} LPA\",\n",
    "        \"Location\": df.loc[i, \"Location\"],\n",
    "        \"Skills\": df.loc[i, \"Skills\"],\n",
    "        \"Combined_text\": df.loc[i, \"combined_text\"]\n",
    "    }\n",
    "    for i in range(len(df))\n",
    "}\n",
    "\n",
    "# Confirm index size\n",
    "print(f\"✅ FAISS index contains {index.ntotal} job entries.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8246b-21ce-450a-a7d6-a850ad8af78c",
   "metadata": {},
   "source": [
    "### **📌 Save FAISS Index Along With Meta Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c4b878b-57f3-4671-901f-cd9814132823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS index and metadata saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "## Save the FAISS Index\n",
    "#FAISS provides a built-in method to save the index as a binary file:\n",
    "\n",
    "faiss.write_index(index, \"faiss_index.bin\")\n",
    "\n",
    "## Save Job Metadata Separately\n",
    "#Since FAISS only stores embeddings, we must **save job metadata separately** using Python's `pickle`\n",
    "\n",
    "with open(\"job_metadata.pkl\", \"wb\") as f:\n",
    "    pickle.dump(job_metadata_map, f)\n",
    "\n",
    "print(\"✅ FAISS index and metadata saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861335f4-c944-4eb3-aa0e-e590abce5ed3",
   "metadata": {},
   "source": [
    "### **📌 Implement Semantic Search**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780594b8-c74a-4c6b-adcb-6268e3a477e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Matching Jobs:\n",
      "Match Score: 0.5789999961853027\n",
      "{'Job ID': np.int64(1429997), 'Title': 'Associate Engineering Manager/Engineering Manager - Artificial Intelligence/Machine Learning ', 'Job URL': 'https://www.hirist.com/j/associate-engineering-managerengineering-manager-artificial-intelligencemachine-learning-1429997.html', 'Salary': '40 - 50 LPA', 'Location': 'Gurgaon/Gurugram', 'Skills': 'Machine Learning, Deep Learning, Computer Vision, Neural Networks, Artificial Intelligence, Python, SQL', 'Combined_text': 'Job ID: 1429997 | Job Description: Role Overview :We are looking for an Associate Engineering Manager / Engineering Manager - AI/ML with 7-10 years of hands on experience in Artificial Intelligence (AI), Machine Learning (ML), Deep Learning, Computer Vision, and Neural Networks. The ideal candidate should have strong expertise in developing AI/ML models from scratch, along with coding and deployment experience. This is a leadership role that requires technical excellence, hands-on development, and team management.Key Responsibilities :AI/ML Model Development : Design, build, and optimize AI/ML models from scratch, ensuring high performance and scalability.Deep Learning & Computer Vision : Apply cutting-edge techniques in Deep Learning, Neural Networks, and Computer Vision to develop real-world AI solutions.Coding & Deployment : Write clean, efficient, and production-ready code in Python, TensorFlow, PyTorch, Scikit-learn, and related ML frameworks. Deploy AI/ML models in cloud/on-premise environments.Leadership & Mentorship : Lead, mentor, and guide a team of AI/ML engineers, ensuring best practices and continuous learning.Collaboration : Work closely with product managers, data scientists, and software engineers to translate business requirements into AI-powered solutions.Research & Innovation : Stay updated with the latest AI/ML advancements and implement state-of-the art solutions.Performance Optimization : Optimize AI models for efficiency, accuracy, and scalability in production environments.Required Skills & Experience :- 7-10 years of hands-on experience in AI, ML, Deep Learning, and Neural Networks.- Strong coding expertise in Python, TensorFlow, PyTorch, Scikit-learn, OpenCV, and related frameworks.- Experience in building AI/ML models from scratch, including data preprocessing, model training, tuning, and deployment.- Solid understanding of Computer Vision, Natural Language Processing (NLP), and Generative AI techniques.- Experience with MLOps, model versioning, and deployment pipelines (e.g., Docker, Kubernetes, AWS, Azure, GCP).- Strong knowledge of big data technologies, distributed computing, and cloud-based AI solutions.- Proven experience in leading and mentoring engineering teams.- Excellent problem-solving skills and ability to work in a fast-paced environment.Preferred Qualifications :- Masters or Ph.D. in Computer Science, AI, ML, or a related field.- Experience in LLMs (Large Language Models), Transformers, GANs, and Reinforcement Learning.- Exposure to AI ethics, bias mitigation, and explainability techniques. | Title: Associate Engineering Manager/Engineering Manager - Artificial Intelligence/Machine Learning  | Designation: Associate Engineering Manager/Engineering Manager | Min Experience: 6 | Max Experience: 11 | Category ID: 7 | Job URL: https://www.hirist.com/j/associate-engineering-managerengineering-manager-artificial-intelligencemachine-learning-1429997.html | Location: Gurgaon/Gurugram | Company ID: 0 | Company Name: biup | Recruiter ID: 195396 | Recruiter Name: Vimal Kishor | Recruiter Designation: Head of HR | Min Salary: 40 | Max Salary: 50 | Functional Area: ML / DL Engineering | Skills: Machine Learning, Deep Learning, Computer Vision, Neural Networks, Artificial Intelligence, Python, SQL'}\n",
      "--------------------------------------------------\n",
      "Match Score: 0.5633000135421753\n",
      "{'Job ID': np.int64(1429343), 'Title': 'Gen AI Engineer - Artificial Intelligence/Machine Learning ', 'Job URL': 'https://www.hirist.com/j/gen-ai-engineer-artificial-intelligencemachine-learning-1429343.html', 'Salary': '15 - 25 LPA', 'Location': 'Mumbai', 'Skills': 'Generative AI, Artificial Intelligence, Machine Learning, Data Modeling, R, Python, Tensorflow, PyTorch, Data Analytics', 'Combined_text': \"Job ID: 1429343 | Job Description: Job Overview :We are looking for a highly skilled and motivated GenAI/ML Engineer to join our team. The ideal candidate will have a strong background in artificial intelligence and machine learning, and a passion for using these technologies to develop innovative solutions. The GenAI/ML Engineer will be responsible for designing, developing, and implementing AI and ML models to solve complex problems and improve our products and processes.Responsibilities :- Collaborate with cross-functional teams to identify opportunities for leveraging AI/ML technologies to drive business results- Design and develop machine learning models and algorithms to analyze and interpret large datasets- Implement and optimize AI/ML algorithms for real-time or near real-time performance- Work on integrating AI/ML models into production systems and applications- Stay up-to-date with the latest AI/ML technologies and trends to drive innovation and continuous improvement- Communicate and present technical findings and solutions to stakeholders and team membersRequirements :- Bachelor's or Master's degree in Computer Science, Engineering, or related field- Proven experience in developing and deploying AI/ML solutions- Strong programming skills in languages such as Python, R, or Java- Experience with machine learning frameworks such as TensorFlow, Keras, Scikit-learn, or PyTorch- Solid understanding of AI/ML algorithms, data structures, and statistical models- Excellent problem-solving and analytical skills- Strong communication and collaboration skillsIf you have a passion for cutting-edge AI/ML technologies and want to make an impact in a dynamic and fast-paced environment, we'd love to hear from you. Join us in shaping the future of AI and ML. Apply now!Roles and Responsibilities of GenAI/ML Engineer :1. Develop and implement machine learning algorithms and models to solve complex business problems.2. Design and build AI-powered solutions for data analysis, prediction, and recommendation.3. Collaborate with data scientists and software engineers to integrate machine learning models into production systems.4. Research and experiment with new algorithms and techniques to improve the performance of AI and ML systems.5. Analyze and interpret large datasets to identify patterns and insights that can drive business decision-making.6. Optimize and fine-tune machine learning models for accuracy, scalability, and efficiency.7. Stay up-to-date with the latest advancements in AI and machine learning technologies and apply them to solve real-world problems.8. Work closely with cross-functional teams to understand the business requirements and translate them into technical solutions.9. Participate in code reviews, documentation, and knowledge sharing to maintain high-quality and well-documented ML implementations.10. Provide technical expertise and guidance to junior team members and contribute to the overall growth of the AI and ML engineering practice within the organization. Overall, the primary responsibility of a GenAI/ML Engineer is to design, develop, and deploy AI/ML solutions to deliver actionable insights and drive business value. | Title: Gen AI Engineer - Artificial Intelligence/Machine Learning  | Designation: Gen AI Engineer | Min Experience: 3 | Max Experience: 5 | Category ID: 7 | Job URL: https://www.hirist.com/j/gen-ai-engineer-artificial-intelligencemachine-learning-1429343.html | Location: Mumbai | Company ID: 4564 | Company Name: exponentia.ai | Recruiter ID: 149673 | Recruiter Name: swapna | Recruiter Designation: Senior Associate - Talent Acquisition | Min Salary: 15 | Max Salary: 25 | Functional Area: ML / DL / AI Research | Skills: Generative AI, Artificial Intelligence, Machine Learning, Data Modeling, R, Python, Tensorflow, PyTorch, Data Analytics\"}\n",
      "--------------------------------------------------\n",
      "Match Score: 0.5631999969482422\n",
      "{'Job ID': np.int64(1433797), 'Title': 'Artificial Intelligence Engineer - Machine Learning ', 'Job URL': 'https://www.hirist.com/j/artificial-intelligence-engineer-machine-learning-1433797.html', 'Salary': '20 - 60 LPA', 'Location': 'Gurgaon/Gurugram', 'Skills': 'Artificial Intelligence, Machine Learning, NLP, Data Modeling, Data Analytics, Python, PyTorch, Tensorflow, Deep Learning, SQL, NoSQL', 'Combined_text': 'Job ID: 1433797 | Job Description: Title : AI EngineerLocation : Gurugram, India, OnsiteEducation : B.Tech in Computer Science (IIT Only)Experience : 6 months - 2 yearsJob Description :We are looking for a highly skilled AI Engineer with a B.Tech in Computer Science from IIT and 6 months to 2 years of experience in AI, Machine Learning, and Deep Learning. This is an exciting opportunity to work on cutting-edge AI solutions in a dynamic and innovative environment.Key Responsibilities :- Develop and deploy AI/ML models for real-world applications.- Work with large-scale datasets, perform data preprocessing, and feature engineering.- Implement deep learning algorithms using frameworks like TensorFlow, PyTorch, and Keras.- Optimize and fine-tune AI models for performance, scalability, and accuracy.- Collaborate with software engineers and data scientists to integrate AI solutions into production.- Stay up to date with the latest advancements in AI, ML, and NLP technologies.- Conduct research and develop innovative AI-driven solutions.Required Skills & Qualifications :- B.Tech in Computer Science from IIT (Mandatory).- 6 months - 2 years of hands-on experience in AI, ML, or Data Science.- Proficiency in Python, TensorFlow, PyTorch, and Scikit-Learn.- Strong understanding of Machine Learning algorithms, Deep Learning, and NLP.- Experience with data preprocessing, feature extraction, and model evaluation.- Familiarity with cloud platforms (AWS, GCP, or Azure) for AI deployments.- Knowledge of SQL, NoSQL databases, and Big Data technologies is a plus.- Excellent problem-solving skills and ability to work in a fast-paced environment.Why Join Us?- Work on cutting-edge AI projects- Opportunity to grow in a highly skilled and innovative team- Exposure to real-world AI implementations- Fast-paced, learning-driven work environment | Title: Artificial Intelligence Engineer - Machine Learning  | Designation: Artificial Intelligence Engineer | Min Experience: 1 | Max Experience: 2 | Category ID: 7 | Job URL: https://www.hirist.com/j/artificial-intelligence-engineer-machine-learning-1433797.html | Location: Gurgaon/Gurugram | Company ID: 0 | Company Name: USIL Technologies | Recruiter ID: 183635 | Recruiter Name: Nupur Singh | Recruiter Designation: HR Talent Acquisition Partner | Min Salary: 20 | Max Salary: 60 | Functional Area: ML / DL / AI Research | Skills: Artificial Intelligence, Machine Learning, NLP, Data Modeling, Data Analytics, Python, PyTorch, Tensorflow, Deep Learning, SQL, NoSQL'}\n",
      "--------------------------------------------------\n",
      "Match Score: 0.5630000233650208\n",
      "{'Job ID': np.int64(1401993), 'Title': 'Generative AI Developer - NLP/Neural Networks ', 'Job URL': 'https://www.hirist.com/j/generative-ai-developer-nlpneural-networks-1401993.html', 'Salary': '12 - 20 LPA', 'Location': 'Bangalore', 'Skills': 'Generative AI, NLP, Neural Networks, Deep Learning, Artificial Intelligence, Machine Learning, Python, Tensorflow, PyTorch, Version Control System, MLOps', 'Combined_text': 'Job ID: 1401993 | Job Description: Job Title / Role : Gen AI Developer. Key Skills : Gen AI, Natural Language Processing (NLP), Neural Networks (NN), Deep Learning(DL). Location : Bangalore. Mode : Work from office. Experience : - Experience in AI/ML with a strong focus on NLP and Neural Networks.- Extensive hands-on experience in developing and deploying generative AI models for NLP tasks such as text generation, conversational agents, and natural language understanding. - Proven experience with state-of-the-art neural network architectures (Transformers, CNNs, RNNs, LSTMs) and fine-tuning large language models (e.g, GPT, BERT). - Demonstrated experience working with high-scale datasets and applying advanced data processing techniques for NLP. Technical Skills : - Proficient in programming languages such as Python with experience in AI/ML libraries (e.g, TensorFlow, PyTorch, Hugging Face, Keras). - Deep expertise in NLP libraries and tools (e.g, SpaCy, NLTK, transformers by Hugging Face). - Hands-on experience with model deployment in production environments using cloud platforms (Azure, AWS, GCP). - Solid understanding of MLOps practices including model deployment, monitoring, and continuous learning.- Proficiency with version control, collaboration tools (Git, JIRA), and CI/CD pipelines. | Title: Generative AI Developer - NLP/Neural Networks  | Designation: Generative AI Developer | Min Experience: 3 | Max Experience: 7 | Category ID: 7 | Job URL: https://www.hirist.com/j/generative-ai-developer-nlpneural-networks-1401993.html | Location: Bangalore | Company ID: 0 | Company Name: Wiingy Pvt Ltd | Recruiter ID: 194922 | Recruiter Name: Wiingy | Recruiter Designation:  Senior Recruiter | Min Salary: 12 | Max Salary: 20 | Functional Area: ML / DL Engineering | Skills: Generative AI, NLP, Neural Networks, Deep Learning, Artificial Intelligence, Machine Learning, Python, Tensorflow, PyTorch, Version Control System, MLOps'}\n",
      "--------------------------------------------------\n",
      "Match Score: 0.5586000084877014\n",
      "{'Job ID': np.int64(1431186), 'Title': 'Lead Data Scientist - Machine Learning Solutions ', 'Job URL': 'https://www.hirist.com/j/lead-data-scientist-machine-learning-solutions-1431186.html', 'Salary': '28 - 36 LPA', 'Location': 'Remote', 'Skills': 'Data Science, Data Scientist, Python, Pandas, Data Analytics, Data Visualization, NLP, LLM, Cloud, Machine Learning', 'Combined_text': \"Job ID: 1431186 | Job Description: About the Role :Duration : 6 months + ExtendableLocation : RemoteTimings : General ISTNotice Period : Within 15 days or immediate joinerExperience : Minimum 8 Years of relevant expInterview Rounds : 4Job Overview : We are seeking a highly skilled and experienced Senior Data Scientist with expertise in Machine Learning (ML), Natural Language Processing (NLP), Generative AI (GenAI), and Deep Learning (DL).Mandatory Skills :- 8+ years of work experience in writing code in Python- Experience in using various Python libraries like Pandas, NumPy- Experience in writing good quality code in Python and code refactoring techniques (e.g., IDE's - PyCharm, - Visual Studio Code; Libraries - Pylint, pycodestyle, pydocstyle, Black)- Strong experience on AI assisted coding experience.- AI-assisted coding for existing IDE's like vscode.- Experimented multiple AI-assisted tools and done research around it.- Deep understanding of data structures, algorithms, and excellent problem-solving skills- Experience in Python, Exploratory Data Analysis (EDA), Feature Engineering, Data Visualisation- Machine Learning libraries like Scikit-learn, XGBoost- Experience in CV, NLP or Time Series.- Experience in building models for ML tasks (Regression, Classification)- Should have Experience into LLM, LLM Fine Tuning, Chatbot, RAG Pipeline Chatbot, LLM Solution, Multi - Modal LLM Solution, GPT, Prompt, Prompt Engineering, Tokens, Context Window, Attention Mecanism, Embeddings- Experience of model training and serving on any of the cloud environments (AWS, GCP, Azure)- Experience in distributed training of models on Nvidia GPUs- Familiarity in Dockerizing the model and creating model endpoints (Rest or gRPC)- Strong working knowledge of source code control tools such as Git, Bitbucket- Prior experience of designing, developing and maintaining Machine Learning solutions through its Life Cycle is highly advantageous- Strong drive to learn and master new technologies and techniques- Strong communication and collaboration skills- Good attitude and self-motivated- Open communication, flat hierarchy, plenty of individual responsibilityWork environment: We have an environment to create an impact on the client's business and transform innovative ideas into reality. Even our junior engineers get the opportunity to work on different product features in complex domains | Title: Lead Data Scientist - Machine Learning Solutions  | Designation: Lead Data Scientist | Min Experience: 8 | Max Experience: 12 | Category ID: 7 | Job URL: https://www.hirist.com/j/lead-data-scientist-machine-learning-solutions-1431186.html | Location: Remote | Company ID: 0 | Company Name: GAIUS HYPERLOCAL PRIVATE LIMITED | Recruiter ID: 176630 | Recruiter Name: Devi Priya | Recruiter Designation: Human resource  | Min Salary: 28 | Max Salary: 36 | Functional Area: ML / DL / AI Research | Skills: Data Science, Data Scientist, Python, Pandas, Data Analytics, Data Visualization, NLP, LLM, Cloud, Machine Learning\"}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 🔹 SEMANTIC SEARCH FUNCTION\n",
    "# ============================\n",
    "\n",
    "\"\"\"\n",
    "This function takes a user's query, generates an embedding, and finds the closest jobs using FAISS.\n",
    "It returns the top `k` matching jobs.\n",
    "\"\"\"\n",
    "# Function to generate embeddings\n",
    "def get_embedding(text):\n",
    "    return np.array(embedding_model.encode(text, normalize_embeddings=True))\n",
    "\n",
    "\n",
    "# Function to search jobs using FAISS\n",
    "def search_jobs(query, top_k=5):\n",
    "    query_embedding = get_embedding(query)  # Convert query into an embedding\n",
    "    distances, indices = index.search(query_embedding.reshape(1, -1), top_k)  # Search FAISS\n",
    "\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        if idx == -1:\n",
    "            continue  # Ignore invalid indices\n",
    "\n",
    "        metadata = job_metadata_map[idx]  # Fetch job metadata\n",
    "        combined_text = metadata[\"Combined_text\"]\n",
    "        #metadata.pop(\"Combined_text\")\n",
    "        score = round(1 / (1 + distances[0][i]), 4)  # Convert L2 distance to similarity score\n",
    "\n",
    "        results.append({\"metadata\":metadata, \"score\":score, \"combined_text\":combined_text})\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example Query\n",
    "query = \"Looking for a remote AI job with deep learning expertise\"\n",
    "results = search_jobs(query)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nTop Matching Jobs:\")\n",
    "for row in results:\n",
    "    print(f\"Match Score: {row['score']}\\n{row['metadata']}\\n{'-'*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa348b6-3665-4cfc-b91b-09adcede67ed",
   "metadata": {},
   "source": [
    "### **📌 Test Queries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f17beff-36be-4d61-9364-1703b8eda775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Test Query 1: AI engineer role with experience in reinforcement learning and NLP\n",
      "  - Match Score: 0.5559999942779541\n",
      "  - Title: Generative AI Developer - NLP/Neural Networks \n",
      "  - Job URL: https://www.hirist.com/j/generative-ai-developer-nlpneural-networks-1401993.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Generative AI, NLP, Neural Networks, Deep Learning, Artificial Intelligence, Machine Learning, Python, Tensorflow, PyTorch, Version Control System, MLOps\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5468999743461609\n",
      "  - Title: Senior Data Scientist - Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/senior-data-scientist-generative-ai-1427666.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Data Scientist, Data Science, Generative AI, NLP, Machine Learning, Artificial Intelligence, Tensorflow, LLM, Spark, Hadoop, Data Visualization\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5454999804496765\n",
      "  - Title: Accenture - Consultant - LLM/Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/accenture-consultant-llmgenerative-ai-1406219.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Data Science, NLP, IT Consulting, Generative AI, LLM, Deep Learning, Machine Learning, GPT\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5382999777793884\n",
      "  - Title: CAMP Systems International- Data Scientist - Artificial Intelligence/Machine Learning \n",
      "  - Job URL: https://www.hirist.com/j/camp-systems-international-data-scientist-artificial-intelligencemachine-learning-1431439.html\n",
      "  - Location: Hyderabad\n",
      "  - Skills: Generative AI, Artificial Intelligence, Machine Learning, Python, Time Series Analysis, Tensorflow, PyTorch, LLM, RAG, AWS, NLP\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.527999997138977\n",
      "  - Title: Machine Learning Engineer - Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/machine-learning-engineer-generative-ai-1428419.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Machine Learning, Python, Artificial Intelligence, Generative AI, Deep Learning, RAG, Data Structure, Algorithm, Big Data\n",
      "--------------------------------------------------\n",
      "\n",
      "🔹 Test Query 2: Remote job for a Python developer with cloud computing expertise\n",
      "  - Match Score: 0.5630000233650208\n",
      "  - Title: Gapblue - Senior Python Developer - Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/gapblue-senior-python-developer-generative-ai-1423311.html\n",
      "  - Location: Kerala\n",
      "  - Skills: Python, Generative AI, Machine Learning, Artificial Intelligence, GPT, AWS, Azure\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5339999794960022\n",
      "  - Title: Data Engineer - Visualization Tools \n",
      "  - Job URL: https://www.hirist.com/j/data-engineer-visualization-tools-4-14-yrs-1433776.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Python, .Net, ETL, C#, Entity Framework, SQL, Data Visualization Tools, PowerApps, Power BI, Tableau, Azure Databricks\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5310999751091003\n",
      "  - Title: Artificial Intelligence/Machine Learning Engineer \n",
      "  - Job URL: https://www.hirist.com/j/artificial-intelligencemachine-learning-engineer-1433528.html\n",
      "  - Location: Hyderabad\n",
      "  - Skills: Artificial Intelligence, Machine Learning, PyTorch, Tensorflow, Cloud Services, Statistical Analyst, Mathematical Modeling, Version Control System\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5242000222206116\n",
      "  - Title: Rosemallow Technologies - Machine Learning Engineer - Big Data Technologies \n",
      "  - Job URL: https://www.hirist.com/j/rosemallow-technologies-machine-learning-engineer-big-data-technologies-1433762.html\n",
      "  - Location: Mumbai\n",
      "  - Skills: Data Science, Machine Learning, Python, Tensorflow, Hadoop, Spark, SQL, Big Data, Artificial Intelligence\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5212000012397766\n",
      "  - Title: Machine Learning Platform Engineer \n",
      "  - Job URL: https://www.hirist.com/j/machine-learning-platform-engineer-1433719.html\n",
      "  - Location: Remote\n",
      "  - Skills: Machine Learning, AWS, Azure, Python, SQL, MLOps, Google Cloud Platform, CI/CD Pipeline, ETL, Cloud Services, Generative AI\n",
      "--------------------------------------------------\n",
      "\n",
      "🔹 Test Query 3: Senior data scientist position in Bangalore with at least 5 years of experience\n",
      "  - Match Score: 0.5691999793052673\n",
      "  - Title: Hexaware Technologies - Practice Lead - Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/hexaware-technologies-practice-lead-generative-ai-1433739.html\n",
      "  - Location: Chennai\n",
      "  - Skills: Generative AI, Data Science, Data Scientist, Artificial Intelligence, GTM System, NLP, Machine Learning, Deep Learning, Azure Databricks, Data Mining, Practice Management\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5587000250816345\n",
      "  - Title: Data Engineer - SQL/Java \n",
      "  - Job URL: https://www.hirist.com/j/data-engineer-sqljava-1433344.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Data Engineering, Data Pipeline, Data Quality, SQL, Data Modeling, Python, Java, Apache Spark, Apache Airflow, Azure Databricks, Snowflake DB\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5455999970436096\n",
      "  - Title: Rebel Foods - Data Scientist - Deep Learning/Machine Learning \n",
      "  - Job URL: https://www.hirist.com/j/rebel-foods-data-scientist-deep-learningmachine-learning-1433877.html\n",
      "  - Location: Mumbai\n",
      "  - Skills: Data Science, Data Scientist, Deep Learning, Machine Learning, Neural Networks, Computer Vision, NLP, Predictive Modeling, Python, SQL\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5419999957084656\n",
      "  - Title: Data Scientist - Python Programming \n",
      "  - Job URL: https://www.hirist.com/j/data-scientist-python-programming-1433786.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Data Science, Data Scientist, Python, Pandas, Numpy, Signal Processing, Machine Learning, Tensorflow, PyTorch, Time Series Analysis, SQL\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5346999764442444\n",
      "  - Title: Mphasis - Salesforce Data Cloud Consultant \n",
      "  - Job URL: https://www.hirist.com/j/mphasis-salesforce-data-cloud-consultant-1424672.html\n",
      "  - Location: US\n",
      "  - Skills: Salesforce, Solution Design, Solution Implementation, Customer Data Platform, Data Strategy, Data Modeling, Data Management, SFDC Sales Cloud, Salesforce Service Cloud, Salesforce Integration\n",
      "--------------------------------------------------\n",
      "\n",
      "🔹 Test Query 4: Startup job with focus on LLM, generative AI, and multi-modal learning\n",
      "  - Match Score: 0.5569999814033508\n",
      "  - Title: DAZN - Data Scientist - Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/dazn-data-scientist-generative-ai-1423163.html\n",
      "  - Location: Hyderabad\n",
      "  - Skills: Data Science, Data Scientist, Numpy, Pandas, Machine Learning, Generative AI, LLM\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5418999791145325\n",
      "  - Title: Senior Data Scientist - NLP/Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/senior-data-scientist-nlpgenerative-ai-1434615.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Data Science, Data Scientist, NLP, LLM, Deep Learning, Statistical Modeling, Generative AI, Python, Big Data\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5393000245094299\n",
      "  - Title: Data Scientist - NLP/Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/data-scientist-nlpgenerative-ai-1421444.html\n",
      "  - Location: Others\n",
      "  - Skills: Data Science, NLP, Data Scientist, Python, R, Tensorflow, PyTorch, LLM, Artificial Intelligence, Computer Vision, Generative AI\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5383999943733215\n",
      "  - Title: MSRcosmos - AI/ML Architect - Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/msrcosmos-aiml-architect-generative-ai-1423609.html\n",
      "  - Location: Hyderabad\n",
      "  - Skills: Artificial Intelligence, Machine Learning, Data Science, Data Scientist, Generative AI, LLM, Python, Data Architect, Tensorflow, PyTorch\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5356000065803528\n",
      "  - Title: Generative AI Engineer - PyTorch/Tensorflow \n",
      "  - Job URL: https://www.hirist.com/j/generative-ai-engineer-pytorchtensorflow-1420120.html\n",
      "  - Location: Remote\n",
      "  - Skills: Generative AI, RAG, Data Science, Artificial Intelligence, LLM, Machine Learning, PyTorch, Tensorflow, NLP, SQL\n",
      "--------------------------------------------------\n",
      "\n",
      "🔹 Test Query 5: Internship in machine learning with mentorship from experienced researchers\n",
      "  - Match Score: 0.5153999924659729\n",
      "  - Title: Lead Engineer - Artificial Intelligence/Machine Learning \n",
      "  - Job URL: https://www.hirist.com/j/lead-engineer-artificial-intelligencemachine-learning-1431073.html\n",
      "  - Location: Udaipur\n",
      "  - Skills: Machine Learning, Artificial Intelligence, Data Scientist, Data Science, LLM, SQL, Python, Data Structure, Algorithm\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.510200023651123\n",
      "  - Title: Associate Manager - Machine Learning \n",
      "  - Job URL: https://www.hirist.com/j/associate-manager-machine-learning-8-16-yrs-1434331.html\n",
      "  - Location: Gurgaon/Gurugram\n",
      "  - Skills: Machine Learning, NLP, Python, Data Modeling, Artificial Intelligence, SQL, Predictive Modeling, LLM, Data Analytics\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5087000131607056\n",
      "  - Title: Senior Machine Learning Engineer - Python \n",
      "  - Job URL: https://www.hirist.com/j/senior-machine-learning-engineer-python-1430877.html\n",
      "  - Location: Anywhere in India/Multiple Locations\n",
      "  - Skills: Machine Learning, Artificial Intelligence, Python, SQL, Data Science\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.508400022983551\n",
      "  - Title: Centific - Machine Learning Lead \n",
      "  - Job URL: https://www.hirist.com/j/centific-machine-learning-lead-1427597.html\n",
      "  - Location: Hyderabad\n",
      "  - Skills: Machine Learning, AWS, Python, Tensorflow, PyTorch, Statistical Modeling, Azure, Google Cloud Platform\n",
      "--------------------------------------------------\n",
      "  - Match Score: 0.5072000026702881\n",
      "  - Title: DigiHelic Solutions - Snowflake Developer - Machine Learning & Generative AI \n",
      "  - Job URL: https://www.hirist.com/j/digihelic-solutions-snowflake-developer-machine-learning-generative-ai-1433636.html\n",
      "  - Location: Bangalore\n",
      "  - Skills: Snowflake DB, Machine Learning, Generative AI, Python, SQL, Pandas, Deep Learning, PyTorch, LLM, NLP, Chatbot\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    \"AI engineer role with experience in reinforcement learning and NLP\",\n",
    "    \"Remote job for a Python developer with cloud computing expertise\",\n",
    "    \"Senior data scientist position in Bangalore with at least 5 years of experience\",\n",
    "    \"Startup job with focus on LLM, generative AI, and multi-modal learning\",\n",
    "    \"Internship in machine learning with mentorship from experienced researchers\"\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_queries):\n",
    "    print(f\"\\n🔹 Test Query {i+1}: {q}\")\n",
    "    results = search_jobs(q)  # Get results\n",
    "\n",
    "    for row in results:  # Loop through results (dictionaries)\n",
    "        job = row[\"metadata\"]  # Extract metadata\n",
    "        score = row[\"score\"]  # Extract match score\n",
    "\n",
    "        print(f\"  - Match Score: {score}\")\n",
    "        print(f\"  - Title: {job['Title']}\")\n",
    "        print(f\"  - Job URL: {job['Job URL']}\")\n",
    "        print(f\"  - Location: {job['Location']}\")\n",
    "        print(f\"  - Skills: {job['Skills']}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db587b9d-9837-4828-8f7f-b80a6b1fbdc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Example RAG-based question\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_rag_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat are the top-paying Data Engineering jobs in Bangalore?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mgenerate_rag_response\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      8\u001b[0m job_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m retrieved_jobs])\n\u001b[0;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mYou are an AI job assistant. You will be asked a question related to jobs, provide your response based over the context provided only.\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124mDo not mention anything about context.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124mAnswer the user\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o-mini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\resources\\chat\\completions\\completions.py:879\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    876\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    877\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    878\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1289\u001b[0m     )\n\u001b[1;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1056\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1055\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1105\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1103\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\openai\\_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1080\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "### Integrate ChatGPT for RAG\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"PUT_YOUR_OPENAI_API_KEY\"\n",
    "\n",
    "def generate_rag_response(query):\n",
    "    retrieved_jobs = search_jobs(query, 10)\n",
    "    job_context = \"\\n\".join([row[\"combined_text\"] for row in retrieved_jobs])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an AI job assistant. You will be asked a question related to jobs, provide your response based over the context provided only.\n",
    "    Do not mention anything about context.\n",
    "    Here is the context for the give job query:\n",
    "    {job_context}\n",
    "    \n",
    "    Answer the user's query: {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example RAG-based question\n",
    "print(generate_rag_response(\"What are the top-paying Data Engineering jobs in Bangalore?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf3eea-7010-4d94-8681-c379453426c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a fresh graduate aiming for a data analyst role, the top sought skills to learn include:\n",
      "\n",
      "1. **Excel Proficiency**: Understanding data formatting, sorting, and using functions like pivot tables and IF statements.\n",
      "2. **SQL**: Familiarity with SQL commands for data retrieval and manipulation, as it's essential for working with databases.\n",
      "3. **Data Visualization**: Experience with tools like Tableau or Power BI for creating interactive dashboards and reports.\n",
      "4. **Analytical Thinking**: Ability to interpret data patterns and draw meaningful conclusions from datasets.\n",
      "5. **Programming Skills**: Basics of Python or R for data manipulation and analysis.\n",
      "6. **Statistical Knowledge**: Understanding basic statistical concepts and methodologies for data analysis.\n",
      "7. **Data Cleaning and Preparation**: Skills in filtering, cleaning, and organizing data to ensure accuracy and quality.\n",
      "8. **Communication Skills**: Ability to clearly explain findings and data insights to non-technical stakeholders.\n",
      "\n",
      "Focusing on these skills will significantly enhance your profile for entry-level data analyst positions.\n"
     ]
    }
   ],
   "source": [
    "# Example RAG-based question\n",
    "print(generate_rag_response(\"Tell me top sought skills for a fresh graduate related to data analyst role that I should learn\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f0254d-bb5d-407a-aa42-093efaac09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To enhance your Power BI skills and improve your job prospects, consider focusing on the following areas:\n",
      "\n",
      "1. **DAX (Data Analysis Expressions)**: Learn to write complex formulas for data calculations and analysis in Power BI.\n",
      "2. **Data Modeling**: Understand how to create and optimize data models to support business intelligence needs.\n",
      "3. **SQL Proficiency**: Gain strong skills in SQL for data extraction and manipulation.\n",
      "4. **ETL (Extract, Transform, Load)**: Familiarize yourself with ETL processes to handle data more effectively.\n",
      "5. **Data Visualization Best Practices**: Master the principles of designing effective visualizations.\n",
      "6. **Azure Data Services**: Knowledge of Azure services related to data storage and analytics can be beneficial.\n",
      "7. **Power Query**: Learn to clean and transform data using Power Query.\n",
      "\n",
      "Here are some job opportunities that align with enhancing your skills:\n",
      "\n",
      "1. **Data Analyst - Power BI**\n",
      "   - Job Link: [Data Analyst - Power BI](https://www.hirist.com/j/data-analyst-power-bi-1434571.html)\n",
      "   - Skills Required:\n",
      "     - Power BI\n",
      "     - DAX\n",
      "     - SQL\n",
      "     - Data Modeling\n",
      "     - Data Visualization\n",
      "\n",
      "2. **Senior Power BI Developer - ETL/SQL**\n",
      "   - Job Link: [Senior Power BI Developer](https://www.hirist.com/j/senior-power-bi-developer-etlsql-1433069.html)\n",
      "   - Skills Required:\n",
      "     - Power BI (DAX, Power Query)\n",
      "     - SQL Server\n",
      "     - ETL processes\n",
      "     - Data Warehousing\n",
      "     - Data Visualization\n",
      "\n",
      "3. **Power BI Developer - Power Query M/SQL**\n",
      "   - Job Link: [Power BI Developer](https://www.hirist.com/j/power-bi-developer-power-query-msql-1434115.html)\n",
      "   - Skills Required:\n",
      "     - Power BI\n",
      "     - DAX\n",
      "     - SQL\n",
      "     - Data Modeling\n",
      "     - ETL\n",
      "\n",
      "4. **Power BI Developer - Data Visualization**\n",
      "   - Job Link: [Power BI Developer - Data Visualization](https://www.hirist.com/j/power-bi-developer-data-visualization-1429998.html)\n",
      "   - Skills Required:\n",
      "     - Power BI\n",
      "     - Data Visualization\n",
      "     - DAX\n",
      "     - Data Modeling\n",
      "     - Strong Analytical Skills\n",
      "\n",
      "5. **Power Platform Senior Developer**\n",
      "   - Job Link: [Power Platform Senior Developer](https://www.hirist.com/j/power-platform-senior-developer-6-10-yrs-1432591.html)\n",
      "   - Skills Required:\n",
      "     - Power Apps\n",
      "     - Power Automate\n",
      "     - SQL Server Integration\n",
      "     - Low-code Development\n",
      "     - Strong Problem-Solving Skills\n",
      "\n",
      "By focusing on these additional skills and applying to these job opportunities, you can significantly increase your chances of getting shortlisted and securing a position in the data analysis field.\n"
     ]
    }
   ],
   "source": [
    "# Example RAG-based question\n",
    "print(generate_rag_response(\"\"\"I did a course on powerbi, suggest me what shall I learn more \n",
    "                                and give me some jobs(along with job link) where i can apply after learning those extra skills.\n",
    "                                Also create skill section that I can add to my resume for each of the job to have better chances of getting shortlisted.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87135c33-6461-4430-aecf-44c336449a84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **📌 Summary & Conclusion for Notebook**\n",
    "These sections summarize your analysis and provide key takeaways.\n",
    "\n",
    "### **📌 Summary**\n",
    "This project automates job searches on **Hirist** for **AI and Data Science roles**. The script:\n",
    "1. **Fetches job listings dynamically** using web scraping.\n",
    "2. Extracts **job details**, including **title, company, location, salary, and skills**.\n",
    "3. **Presents data visually** using **graphs on skills, salaries, and job locations**.\n",
    "4. **Uses GPT to generate insights** on job trends.\n",
    "5. Allows users to **interactively search jobs** using a **Streamlit app**.\n",
    "\n",
    "### **📌 Conclusion**\n",
    "✅ This solution provides a **data-driven job search experience**.  \n",
    "✅ **Real-time insights** help job seekers make informed decisions.  \n",
    "✅ The **Streamlit interface** makes it user-friendly.  \n",
    "✅ Future improvements can include **historical trend analysis** and **salary predictions**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb1e2bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
